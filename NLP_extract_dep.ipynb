{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 14.0MB/s]\n",
      "2021-02-08 08:41:47 INFO: Downloading default packages for language: en (English)...\n",
      "2021-02-08 08:41:50 INFO: File exists: C:\\Users\\divya\\stanza_resources\\en\\default.zip.\n",
      "2021-02-08 08:41:58 INFO: Finished downloading models and saved to C:\\Users\\divya\\stanza_resources.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanza.download('en')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('clean_unsup.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "stop = [\"br\"]\n",
    "\n",
    "def apply_cleaning_function_to_list(X):\n",
    "    cleaned_X = []\n",
    "    for element in X:\n",
    "        cleaned_X.append(clean_text(element))\n",
    "    return cleaned_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def clean_text(raw_text):\n",
    "    # Convert text to lower case\n",
    "    text = raw_text.lower()\n",
    "    \n",
    "    # Tokenize\n",
    "    #tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    import re\n",
    "    words = re.split(r'\\W+', text)\n",
    "    \n",
    "    # removes punctuation + numbers and keep numbers - (isalpha())\n",
    "    token_words = [w for w in words if w.isalpha()]\n",
    "    \n",
    "    # Stemming\n",
    "    #stemmed_words = [stemming.stem(w) for w in token_words]\n",
    "    from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    stemmed_words = [lemmatizer.lemmatize(w) for w in token_words]\n",
    "    \n",
    "    # Remove stop words\n",
    "    meaningful_words = [w for w in stemmed_words if not w in stops]\n",
    "    meaningful_words = [w for w in meaningful_words if not w in stop]\n",
    "    meaningful_words = [w for w in meaningful_words if not w in string.punctuation]\n",
    "    \n",
    "    # joining meaningful words\n",
    "    joined_words = ( \" \".join(meaningful_words))\n",
    "    \n",
    "    # Return cleaned data\n",
    "    return joined_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the review column text to clean\n",
    "text_to_clean = list(df['review'])\n",
    "\n",
    "# Clean text\n",
    "cleaned_text = apply_cleaning_function_to_list(text_to_clean)\n",
    "#print(cleaned_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean'] = cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./dataset.csv',index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first heard eddie murphy wa going star haunted mansion wa initially disappointed former intern disney world haunted mansion fan wanted serious scary look story surround awesome attraction thought many haunted house movie recently bombed haunting house haunted hill lighter comedic approach haunted mansion may better think case necessarily scariest movie funniest good mix make good unique movie family honestly think movie combine horror type genre family genre saw theater packed full family people laughed gasped clapped end tie ride nice beginning film enjoyed ominous organ music whisked back ride singing bust awesome jennifer tilly great job madame leota really need mention special effect mighty impressive nevertheless movie perfect one story intriguing found bored time acting wa kind stiff rigid unintentionally evers family though good family movie unlike movie imdb rating yahoo grade b good'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('first', 'RB'), ('heard', 'NN'), ('eddie', 'NN'), ('murphy', 'NN'), ('wa', 'NN'), ('going', 'VBG'), ('star', 'NN'), ('haunted', 'VBN'), ('mansion', 'NN'), ('wa', 'NN'), ('initially', 'RB'), ('disappointed', 'JJ'), ('former', 'JJ'), ('intern', 'NN'), ('disney', 'NN'), ('world', 'NN'), ('haunted', 'VBN'), ('mansion', 'NN'), ('fan', 'NN'), ('wanted', 'VBD'), ('serious', 'JJ'), ('scary', 'JJ'), ('look', 'NN'), ('story', 'NN'), ('surround', 'VBD'), ('awesome', 'JJ'), ('attraction', 'NN'), ('thought', 'VBD'), ('many', 'JJ'), ('haunted', 'VBN'), ('house', 'NN'), ('movie', 'NN'), ('recently', 'RB'), ('bombed', 'VBD'), ('haunting', 'JJ'), ('house', 'NN'), ('haunted', 'VBN'), ('hill', 'JJ'), ('lighter', 'RBR'), ('comedic', 'JJ'), ('approach', 'NN'), ('haunted', 'VBN'), ('mansion', 'NN'), ('may', 'MD'), ('better', 'VB'), ('think', 'VB'), ('case', 'NN'), ('necessarily', 'RB'), ('scariest', 'JJS'), ('movie', 'NN'), ('funniest', 'JJS'), ('good', 'JJ'), ('mix', 'NN'), ('make', 'VBP'), ('good', 'JJ'), ('unique', 'JJ'), ('movie', 'NN'), ('family', 'NN'), ('honestly', 'RB'), ('think', 'VBP'), ('movie', 'NN'), ('combine', 'NN'), ('horror', 'NN'), ('type', 'NN'), ('genre', 'VBD'), ('family', 'NN'), ('genre', 'NN'), ('saw', 'VBD'), ('theater', 'NN'), ('packed', 'VBN'), ('full', 'JJ'), ('family', 'NN'), ('people', 'NNS'), ('laughed', 'VBD'), ('gasped', 'VBD'), ('clapped', 'JJ'), ('end', 'NN'), ('tie', 'NN'), ('ride', 'NN'), ('nice', 'JJ'), ('beginning', 'NN'), ('film', 'NN'), ('enjoyed', 'VBD'), ('ominous', 'JJ'), ('organ', 'JJ'), ('music', 'NN'), ('whisked', 'VBD'), ('back', 'RP'), ('ride', 'NN'), ('singing', 'NN'), ('bust', 'NN'), ('awesome', 'JJ'), ('jennifer', 'NN'), ('tilly', 'RB'), ('great', 'JJ'), ('job', 'NN'), ('madame', 'NN'), ('leota', 'RBR'), ('really', 'RB'), ('need', 'VB'), ('mention', 'NN'), ('special', 'JJ'), ('effect', 'NN'), ('mighty', 'NN'), ('impressive', 'JJ'), ('nevertheless', 'RB'), ('movie', 'NN'), ('perfect', 'JJ'), ('one', 'CD'), ('story', 'NN'), ('intriguing', 'VBG'), ('found', 'VBN'), ('bored', 'JJ'), ('time', 'NN'), ('acting', 'VBG'), ('wa', 'NN'), ('kind', 'NN'), ('stiff', 'JJ'), ('rigid', 'JJ'), ('unintentionally', 'RB'), ('evers', 'NNS'), ('family', 'NN'), ('though', 'IN'), ('good', 'JJ'), ('family', 'NN'), ('movie', 'NN'), ('unlike', 'IN'), ('movie', 'NN'), ('imdb', 'NN'), ('rating', 'NN'), ('yahoo', 'NN'), ('grade', 'NN'), ('b', 'NN'), ('good', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "sentList = nltk.sent_tokenize(df['clean'][1])\n",
    "for line in sentList:\n",
    "    txt_list = nltk.word_tokenize(line)\n",
    "    taggedList = nltk.pos_tag(txt_list)\n",
    "print(taggedList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-08 08:44:22 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-02-08 08:44:22 INFO: Use device: cpu\n",
      "2021-02-08 08:44:22 INFO: Loading: tokenize\n",
      "2021-02-08 08:44:22 INFO: Loading: pos\n",
      "2021-02-08 08:44:22 INFO: Loading: lemma\n",
      "2021-02-08 08:44:22 INFO: Loading: depparse\n",
      "2021-02-08 08:44:23 INFO: Loading: sentiment\n",
      "2021-02-08 08:44:24 INFO: Loading: ner\n",
      "2021-02-08 08:44:26 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['first', 'heard', 'advmod'], ['heard', 'eddie', 'amod'], ['eddie', 'disappointed', 'nsubj'], ['murphy', 'eddie', 'flat'], ['wa', 'eddie', 'flat'], ['going', 'mansion', 'amod'], ['star', 'mansion', 'compound'], ['haunted', 'mansion', 'amod'], ['mansion', 'disappointed', 'nsubj'], ['wa', 'disappointed', 'nsubj'], ['initially', 'disappointed', 'advmod'], ['disappointed', 'ROOT', 'root'], ['former', 'fan', 'amod'], ['intern', 'fan', 'compound'], ['disney', 'world', 'compound'], ['world', 'fan', 'compound'], ['haunted', 'fan', 'amod'], ['mansion', 'fan', 'compound'], ['fan', 'wanted', 'nsubj'], ['wanted', 'disappointed', 'parataxis'], ['serious', 'story', 'amod'], ['scary', 'story', 'amod'], ['look', 'story', 'compound'], ['story', 'wanted', 'obj'], ['surround', 'attraction', 'amod'], ['awesome', 'attraction', 'amod'], ['attraction', 'thought', 'nsubj'], ['thought', 'disappointed', 'conj'], ['many', 'movie', 'amod'], ['haunted', 'house', 'amod'], ['house', 'movie', 'compound'], ['movie', 'bombed', 'nsubj'], ['recently', 'bombed', 'advmod'], ['bombed', 'thought', 'ccomp'], ['haunting', 'house', 'amod'], ['house', 'bombed', 'obj'], ['haunted', 'approach', 'amod'], ['hill', 'lighter', 'advmod'], ['lighter', 'approach', 'amod'], ['comedic', 'approach', 'amod'], ['approach', 'bombed', 'obj'], ['haunted', 'approach', 'amod'], ['mansion', 'think', 'nsubj'], ['may', 'think', 'aux'], ['better', 'think', 'aux'], ['think', 'disappointed', 'conj'], ['case', 'movie', 'compound'], ['necessarily', 'scariest', 'advmod'], ['scariest', 'movie', 'amod'], ['movie', 'mix', 'compound'], ['funniest', 'mix', 'amod'], ['good', 'mix', 'amod'], ['mix', 'make', 'nsubj'], ['make', 'think', 'parataxis'], ['good', 'family', 'amod'], ['unique', 'family', 'amod'], ['movie', 'family', 'compound'], ['family', 'make', 'obj'], ['honestly', 'think', 'advmod'], ['think', 'make', 'parataxis'], ['movie', 'combine', 'compound'], ['combine', 'type', 'compound'], ['horror', 'type', 'compound'], ['type', 'genre', 'compound'], ['genre', 'genre', 'compound'], ['family', 'genre', 'compound'], ['genre', 'saw', 'nsubj'], ['saw', 'think', 'ccomp'], ['theater', 'packed', 'compound'], ['packed', 'family', 'amod'], ['full', 'family', 'amod'], ['family', 'gasped', 'nsubj'], ['people', 'laughed', 'nsubj'], ['laughed', 'family', 'acl:relcl'], ['gasped', 'clapped', 'parataxis'], ['clapped', 'saw', 'conj'], ['end', 'ride', 'compound'], ['tie', 'ride', 'compound'], ['ride', 'film', 'compound'], ['nice', 'film', 'amod'], ['beginning', 'film', 'compound'], ['film', 'enjoyed', 'nsubj'], ['enjoyed', 'clapped', 'parataxis'], ['ominous', 'music', 'amod'], ['organ', 'music', 'compound'], ['music', 'enjoyed', 'obj'], ['whisked', 'enjoyed', 'xcomp'], ['back', 'ride', 'advmod'], ['ride', 'whisked', 'obl'], ['singing', 'enjoyed', 'advcl'], ['bust', 'singing', 'obj'], ['awesome', 'madame', 'amod'], ['jennifer', 'madame', 'compound'], ['tilly', 'madame', 'compound'], ['great', 'madame', 'amod'], ['job', 'madame', 'compound'], ['madame', 'need', 'nsubj'], ['leota', 'need', 'nsubj'], ['really', 'need', 'advmod'], ['need', 'enjoyed', 'conj'], ['mention', 'need', 'xcomp'], ['special', 'effect', 'amod'], ['effect', 'mention', 'obj'], ['mighty', 'impressive', 'advmod'], ['impressive', 'effect', 'amod'], ['nevertheless', 'intriguing', 'advmod'], ['movie', 'intriguing', 'nsubj'], ['perfect', 'story', 'amod'], ['one', 'story', 'nummod'], ['story', 'intriguing', 'nsubj'], ['intriguing', 'time', 'amod'], ['found', 'effect', 'acl'], ['bored', 'time', 'amod'], ['time', 'found', 'obj'], ['acting', 'found', 'advcl'], ['wa', 'acting', 'obj'], ['kind', 'stiff', 'advmod'], ['stiff', 'family', 'amod'], ['rigid', 'family', 'amod'], ['unintentionally', 'stiff', 'advmod'], ['evers', 'family', 'compound'], ['family', 'acting', 'obj'], ['though', 'movie', 'advmod'], ['good', 'movie', 'amod'], ['family', 'movie', 'compound'], ['movie', 'acting', 'obj'], ['unlike', 'rating', 'case'], ['movie', 'rating', 'compound'], ['imdb', 'rating', 'compound'], ['rating', 'good', 'obl'], ['yahoo', 'good', 'compound'], ['grade', 'b', 'compound'], ['b', 'good', 'compound'], ['good', 'movie', 'acl:relcl']]\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline()\n",
    "doc = nlp(df['clean'][1])\n",
    "dep_node = []\n",
    "for dep_edge in doc.sentences[0].dependencies:\n",
    "    dep_node.append([dep_edge[2].text, dep_edge[0].text, dep_edge[1]])\n",
    "print(dep_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature list: [('ride', 'NN'), ('nice', 'JJ'), ('bust', 'NN'), ('awesome', 'JJ'), ('mention', 'NN'), ('special', 'JJ'), ('mighty', 'NN'), ('impressive', 'JJ'), ('movie', 'NN'), ('perfect', 'JJ'), ('kind', 'NN'), ('stiff', 'JJ')] \n",
      "\n",
      "category list: ['ride', 'nice', 'bust', 'awesome', 'mention', 'special', 'mighty', 'impressive', 'movie', 'perfect', 'kind', 'stiff']\n"
     ]
    }
   ],
   "source": [
    "categoryList = []\n",
    "featureList = []\n",
    "for i in range(0,len(taggedList)-1):\n",
    "    if(taggedList[i][1]==\"NN\" and taggedList[i+1][1]==\"JJ\"):\n",
    "        featureList.append(taggedList[i])\n",
    "        categoryList.append(taggedList[i][0])\n",
    "        featureList.append(taggedList[i+1])\n",
    "        categoryList.append(taggedList[i+1][0])\n",
    "print('feature list:',featureList,'\\n')\n",
    "print('category list:',categoryList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature-cluster: [['ride', ['end', 'tie', 'film', 'back']], ['nice', ['film']], ['bust', ['singing']], ['awesome', ['attraction', 'madame']], ['mention', ['effect']], ['special', ['effect']], ['mighty', ['impressive']], ['impressive', ['mighty', 'effect']], ['movie', ['many', 'house', 'bombed', 'case', 'scariest', 'mix', 'family', 'combine', 'intriguing', 'though', 'good', 'family', 'acting', 'rating']], ['perfect', ['story']], ['kind', ['stiff']], ['stiff', ['kind', 'family', 'unintentionally']]]\n"
     ]
    }
   ],
   "source": [
    "fcluster = []\n",
    "for i in featureList:\n",
    "    filist = []\n",
    "    for j in dep_node:\n",
    "        # nsubj ------- subject\n",
    "        # acl:relcl --- relative clause modifier\n",
    "        # obj --------- object\n",
    "        # dobj -------- direct object of a verb is the noun phrase\n",
    "        # advmod ------ adverbial phrase that serves to modify a verb\n",
    "        # amod -------- adjectival phrase that serves to modify the noun\n",
    "        # compound ---- two or more words\n",
    "        if((j[0]==i[0] or j[1]==i[0]) and (j[2] in [\"nsubj\", \"obj\", \"dobj\", \"advmod\",\"amod\",\"compound\"])):\n",
    "            if(j[0]==i[0]):\n",
    "                filist.append(j[1])\n",
    "            else:\n",
    "                filist.append(j[0])\n",
    "    fcluster.append([i[0], filist])\n",
    "print('feature-cluster:',fcluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nice', ['film']], ['awesome', ['attraction', 'madame']], ['special', ['effect']], ['impressive', ['mighty', 'effect']], ['perfect', ['story']], ['stiff', ['kind', 'family', 'unintentionally']]]\n"
     ]
    }
   ],
   "source": [
    "finalcluster = []\n",
    "dic = {}\n",
    "for i in featureList:\n",
    "    dic[i[0]] = i[1]\n",
    "#from the feature list extracting adjectives\n",
    "for i in fcluster:\n",
    "    if(dic[i[0]]==\"JJ\" ):\n",
    "        finalcluster.append(i)\n",
    "print(finalcluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
